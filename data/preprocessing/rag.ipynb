{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d82cf0-f91a-4574-8a54-ed0f4cc00e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from sklearn.manifold import TSNE\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ed239e-5cb0-4e66-8e65-300947f8e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1118ab8d-8005-425e-a247-8edea5a08d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your content directory\n",
    "path = \"../documents/clean/\"\n",
    "\n",
    "# Use DirectoryLoader to recursively find and load all markdown files\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d736e8e1-5ee9-4625-bee7-24e1aae70e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578cb066-a166-4433-abee-52aca30e0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"#\", \"##\", \"###\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6afac59-5a65-435a-a357-84fdcbe52eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 1238\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ff67db-0b7d-4b99-95cc-597c5a24d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_content = [chunk.page_content for chunk in chunks]\n",
    "longest_chunk = max(chunk_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3ae559-bac5-4101-803b-ed17ff5ae844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:942\n"
     ]
    }
   ],
   "source": [
    "print(\"Length:\"+str(len(longest_chunk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414095b6-0366-4703-a813-3b7ac156de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8977bcdc-ff88-4787-b188-53be64381402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the first batch...\n",
      "Batch 1 processed. Vectorstore now has 210 documents.\n",
      "Processing batch 2/6...\n",
      "Batch 2 processed. Vectorstore now has 420 documents.\n",
      "Processing batch 3/6...\n",
      "Batch 3 processed. Vectorstore now has 630 documents.\n",
      "Processing batch 4/6...\n",
      "Batch 4 processed. Vectorstore now has 840 documents.\n",
      "Processing batch 5/6...\n",
      "Batch 5 processed. Vectorstore now has 1050 documents.\n",
      "Processing batch 6/6...\n",
      "Batch 6 processed. Vectorstore now has 1238 documents.\n",
      "\n",
      "Saving FAISS index to ../../db...\n",
      "FAISS index saved successfully.\n"
     ]
    }
   ],
   "source": [
    "### SWITCH TO FAISS\n",
    "\n",
    "# Define the path for the FAISS database\n",
    "db_path = '../../db'\n",
    "\n",
    "# Delete the FAISS directory if it already exists to start fresh\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"Removing existing FAISS directory at: {db_path}\")\n",
    "    shutil.rmtree(db_path)\n",
    "\n",
    "# Ensure the parent directory exists\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "\n",
    "# Define a batch size\n",
    "batch_size = 210  # Number of documents per batch\n",
    "\n",
    "# Check if there are any chunks to process\n",
    "if not chunks:\n",
    "    print(\"No document chunks to process. Exiting.\")\n",
    "else:\n",
    "    num_batches = math.ceil(len(chunks) / batch_size)\n",
    "\n",
    "    # Create the vectorstore with the first batch\n",
    "    print(\"Processing the first batch...\")\n",
    "    first_batch = chunks[:batch_size]\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=first_batch,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    print(f\"Batch 1 processed. Vectorstore now has {vectorstore.index.ntotal} documents.\")\n",
    "\n",
    "    # Add the remaining batches in a loop\n",
    "    for i in range(1, num_batches):\n",
    "        print(f\"Processing batch {i+1}/{num_batches}...\")\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        next_batch = chunks[start_index:end_index]\n",
    "        \n",
    "        # Add the next batch of documents to the existing FAISS index\n",
    "        vectorstore.add_documents(documents=next_batch)\n",
    "        print(f\"Batch {i+1} processed. Vectorstore now has {vectorstore.index.ntotal} documents.\")\n",
    "\n",
    "    # Save the final FAISS index to the specified path\n",
    "    print(f\"\\nSaving FAISS index to {db_path}...\")\n",
    "    vectorstore.save_local(db_path)\n",
    "    print(\"FAISS index saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cfc61-27dd-479a-84b1-c98b4170f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../../vector_db'\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    Chroma(persist_directory=db_path, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Define a batch size\n",
    "batch_size = 210  # Number of documents per batch\n",
    "num_batches = math.ceil(len(chunks) / batch_size)\n",
    "\n",
    "# Create the vectorstore with the first batch\n",
    "first_batch = chunks[:batch_size]\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=first_batch,\n",
    "    embedding=embeddings, \n",
    "    persist_directory=db_path\n",
    ")\n",
    "print(f\"Batch 1 processed. Vectorstore now has {vectorstore._collection.count()} documents.\")\n",
    "\n",
    "# Add the remaining batches in a loop\n",
    "for i in range(1, num_batches):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    next_batch = chunks[start_index:end_index]\n",
    "    \n",
    "    vectorstore.add_documents(documents=next_batch)\n",
    "    print(f\"Batch {i+1} processed. Vectorstore now has {vectorstore._collection.count()} documents.\")\n",
    "\n",
    "print(\"All batches processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ce327-9d11-4401-9298-e4e43a8e1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbab5f-e79f-44d8-ac94-c05a3de47ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# Prework\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce9c18-a604-4c1e-987e-8061705c9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8),\n",
    "    text=[f\"Text: {d[:100]}...\" for d in documents],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51940d0-80d0-45c7-92fb-042acf1e0504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rag-nuke]",
   "language": "python",
   "name": "conda-env-rag-nuke-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
